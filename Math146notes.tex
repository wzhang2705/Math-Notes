\documentclass[11pt]{article}
\textwidth 15cm 
\textheight 21.3cm
\evensidemargin 6mm
\oddsidemargin 6mm
\topmargin -1.1cm
\setlength{\parskip}{1.5ex}


\usepackage[sumlimits,nointlimits,namelimits]{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{comment}

\usepackage[dvips]{color}

\newtheorem {prop}{Proposition}
\newtheorem {conj}{Conjecture}
\newtheorem {cor}{Corollary}
\newtheorem {thm}{Theorem}
\newtheorem {lem}{Lemma}
\newtheorem {ex}{Example}
\newtheorem {fact}{Fact}
\newtheorem{definition}{Definition}

\title{Math146 Notes}
\author{Wen Hui Zhang}

\begin{document}

\section{One}
\subsection{Introduction}
The resultant vector of addition is called the $sum$ of the original vectors, and the rule for their
combination is called the $parallelogram$ $law$.
\paragraph{Parallelogram Law for Vector Addition}
The sum of two vectors x and y that act at the same point P is the vector beginning at P that is represented by the diagonal
of parallelogram having x and y as adjacent sides.
In $x + y$, let $x = (a_1, a_2)$ and $y = (b_1, b_2)$. Then $x + y = (a_1 + b_1, a_2 + b_2)$.

\paragraph{Scalar Multiplication}
Scalar multiplication consists of multiplying the vector by a real number. If the vector $x$ is represented by an arrow, then for any real number $t$, the vector $tx$ is represented by an arrow in the same direction if $t \geq 0$ and in the opposite direction if $t < 0$. The length of the arrow $tx$ is $abs{t}$ times the length of the arrow $x$.
Two nonzero vectors $x$ and $y$ are called parallel if $y = tx$ for some nonzero real number $t$.

\paragraph{Properties:}
\begin{enumerate}
	\item For all vectors $x$ and $y$, $x + y = y + x$.
	\item For all vectors $x$, $y$, and $z$, $(x + y) + z = x + (y + z)$.
	\item There exists a vector denoted $0$ such that $x + 0 = x$ for each vector $x$.
	\item For each vector $x$, there is a vector $y$ such that $x + y = 0$.
	\item For each vector $x$, $1x = x$.
	\item For each pair of real numbers $a$ and $b$ and each vector $x$, $(ab)x = a(bx)$.
	\item For each real number $a$ and each pair of vectors $x$ and $y$, $a(x + y) = ax + ay$.
	\item For each pair of real numbers $a$ and $b$ and each vector $x$, $(a + b)x = ax + bx$.
\end{enumerate}

\paragraph{Equation of a Line}
The equation of a line through $A$ and $B$ where $u$ and $v$ are the vectors beginning at $O$ to $A$ and $B$. Thus an equation of the line through A and B is $x = u + t(u - v)$.
\subsection{Vector Spaces}
A vector space (or linear space) $\textbf{V}$ over a field. $F$ consists of a set on which two operations (called addition and scalar multiplication, respectively) are defined so that for each pair of elements $x, y,$ in $\textbf{V}$ there is a unique element $x + y$ in $\textbf{V}$, amd for each element $a$ in $F$ and each element $x$ in $\textbf{V}$ there is a unique element $ax$ in $\textbf{V}$, such that the following conditions hold.
\begin{enumerate}[label=(VS \arabic*)]   
\setlength{\itemindent}{.25in}      
	\item For all $x, y$ in $\textbf{V}, x + y = y + x$ (commutativity of addition)
	\item For all $x, y, z$ in $\textbf{V}, (x + y) + z = x + (y + z)$ (associativity of addition).
	\item There exists an element in $\textbf{V}$ denoted by $0$ such that $x + 0 = x$ for each $x$ in $\textbf{V}$.
	\item For each element $x$ in $\textbf{V}$ there exists an element $y$ in $\textbf{V}$ such that $x + y = 0$.
	\item For each element $x$ in $\textbf{V}$, $1x = x$.
	\item For each pair of elements $a, b$ in $F$ and each element $x$ in $\textbf{V}$, $(ab)x = a(bx)$.
	\item For each element $a$ in $F$ and each pair of elements $x, y$ in $\textbf{V}$, $a(x + y) = ax + ay$.
	\item For each pair of elements $a, b$ in $F$ and each element $x$ in $\textbf{V}$, $(a + b)x = ax + bx$.
\end{enumerate}
An object of form $(a_1, a_2, ..., a_n)$, where the entries $a_1, a_2, ..., a_n$ are elements of a field $F$, is called an n-tuple with entries from $F$. The elements $a_1, a_2, ..., a_n$ are called the entries or components of the n-tuple. Two n-tuples $(a_1, a_2, ..., a_n)$ and $(b_1, b_2, ..., b_n)$ with entries from a field $F$ are called equal if $a_i = b_i$ for $i = 1, 2, ..., n$.\\
An $m \times n$ matrix with entries from a field $F$ is a rectangular array of the form
\begin{align*}
\left(
\begin{matrix}
a_{11}&a_{12}&\cdots&a_{1n}\\
a_{21}&a_{22}&\cdots&a_{2n}\\
\vdots&\vdots&&\vdots\\
a_{m1}&a_{m2}&\cdots&a_{mn}
\end{matrix}
\right)
\end{align*}

where each entry $a_{ij}$ $(1\leq i \leq m, 1 \leq j \leq n)$ is an element of $F$. The entries $a_{ij}$ with $i = j$ are the diagonal entries of the matrix. The entries $a_{i1}, a_{i2}, ..., a_{in}$ compose the ith row of the matric, and the entries $a_{1j}, a_{2j}, ..., a_{mj}$ compose the jth column of the matrix.\\\\
If the number of rows and columns of a matrix are equal, the matrix is called square. Two $m \times n$ matrices $A$ and $B$ are called equal if all their corresponding entries are equal, that is, if $A_{ij} = B_{ij}$ for $1 \leq i \leq m$ and $1 \leq j \leq n$.

\begin{definition}{Matrix Addition and Scalar Multiplication}
For $A, B \in M_{m \times n}(F)$ and $c \in F$,\\
\begin{align*}
(A + B)_ij = A_ij + B_ij and (cA)_ij = cA_ij\\
\end{align*}
for $1 \leq i \leq m$ and $1 \leq j \leq n$.
\end{definition}

\begin{thm}
If $ x, y,$ and $z$ are vectors in a vector space $\textbf{V}$ such that $x + z = y + z$, then $x = y$.
\indent $Proof.$ There exists a vector $v$ in $\textbf{V}$ such that $z + v = 0$ (VS 4). Thus
\begin{align*}
x &= x + 0 = x + (z + v) = (x + z) + v\\
= (y + z) + v = y + (z + v) = y + 0 = y
\end{align*}
by (VS 2) and (VS 3).
\end{thm}

\begin{thm}
In any vector space $\textbf{V}$, the following statements are true:
\begin{enumerate}[label=\alph*)]
	\item 0$x = 0$ for each $x \in \textbf{V}$.
	\item $(-a)x = -(ax) = a(-x)$ for each $a \in F$ and each $x \in \textbf{V}$.
	\item $a0 = 0$ for each $a \in F$.
\end{enumerate}
\end{thm}
\subsection{Subspaces}
\begin{definition}
A subset $\textbf{W}$ of a vector space $\textbf{V}$ over a field $F$ is called a $\textbf{subspace}$ of $\textbf{V}$ if 
$\textbf{W}$ is a vector space over $F$ with the operations of addition and scalar multiplication defined on $\textbf{V}$ .
\end{definition}
In any vector space $\textbf{V}$, note that $\textbf{V}$  and $\{0\}$ are subspaces. The latter is called the $\textbf{zero subspace}$ of $\textbf{V}$.\\

\begin{comment}
The four properties must hold:
\begin{enumerate}
	\item $x+y \in \textbf{W}$ whenever $x \in \textbf{W}$ and $y \in \textbf{W}$. ($\textbf{W}$ is closed under addition.)
	\item $cx \in \textbf{W}$ whenever $c \in F$ and $x \in \textbf{W}$. ($\textbf{W}$ is closed under scalar multiplication.)
	\item $\textbf{W}$ has a zero vector.
	\item Each vector in $\textbf{W}$ has an additive inverse in $\textbf{W}$.
\end{enumerate}
\end{comment}

\begin{thm}
Let $\textbf{V}$ be a vector space and $\textbf{W}$ a subset of $\textbf{V}$. Then $\textbf{W}$ is a subspace of $\textbf{V}$ if and only if the following three conditions hold for the operations defined in $\textbf{V}$.
\begin{enumerate}[label=(\alph*)]
	\item $0 \in \textbf{W}$.
	\item $x + y \in \textbf{W}$ whenever $x \in \textbf{W}$ and $y \in \textbf{W}$.
	\item $cx \in \textbf{W}$ whenever $c \in F$ and $x \in \textbf{W}$.
\end{enumerate}
\end{thm}

The $\textbf{transpose}$ $A^t$ of an $m \times n$ matrix $A$ is the $n \times m$ matrix obtained from $A$ by interchanging the rows with the columns; that is, $(A^t)_{ij} = A_{ji}$.\\
A $\textbf{symmetric matrix}$ is a matrix $A$ such that $A^t = A$.

\begin{thm}
Any intersection of subspaces of a vector space $\textbf{V}$ is a subspace of $\textbf{V}$.
\end{thm}

\begin{definition}
If $S_1$ and $S_2$ are nonempty subsets of a vector space $\textbf{V}$, then the sum of $S_1$ and $S_2$, denoted $S_1 + S_2$, is the set $\{x+y: x \in S_1$ and $y \in S_2\}$.
\end{definition}

\begin{definition}
A vector space $\textbf{V}$ is called the direct sum of $\textbf{W}_1$ and $\textbf{W}_2$ if $\textbf{W}_1$ and $\textbf{W}_2$ are subspaces of $\textbf{V}$ such that $\textbf{W}_1 \cap \textbf{W}_2 = \{0\}$ and $\textbf{W}_1 + \textbf{W}_2 = \textbf{V}$. We denote that $\textbf{V}$ is the direct sum of $\textbf{W}_1$ and $\textbf{W}_2$ by writing $\textbf{V} = \textbf{W}_1 \oplus \textbf{W}_2$.
\end{definition}

\subsection{Linear Combinations and Systems of Linear Equations}

\begin{definition}
Let $\textbf{V}$ be a vector space and S a nonempty subset f $\textbf{V}$. A vector $v \in \textbf{V}$ is called a $\textbf linear combination$ of vectors of S if there exist a finite number of vectors $u_1, u_2, ..., u_n$ in S and scalars $a_1, a_2, ..., a_n$ in F such that $v = a_1u_1 + a_2u_2 + \cdots + a_nu_n$. In this case we also say that $v$ is a linear combination of $u_1, u_2, ..., a_n$ the $\textbf coefficients$ of the linear combination.
\end{definition}

\begin{definition}{Span}
Let S be a nonempty subset of a vector space $\textbf{V}$. The span of S, denoted span(S), is the set consisting of all linear combinations of the vectors in S. For convenience, we define span$(\emptyset) = \{0\}$.
\end{definition}

\begin{thm}
The span of any subset S of a vector space $\textbf{V}$ is a subspace of $\textbf{V}$. Moreover, any subspace of $\textbf{V}$ that contains S must also contain the span of S.
\end{thm}

\begin{definition}
A subset S of a vector space $\textbf{V}$ generates (or spans) $\textbf{V}$ if span(S) = $\textbf{V}$. In this case, we also say that the vectors of S generate (or span) $\textbf{V}$.
\end{definition}

\subsection{linear dependence and span}
A set of vectors is said to be linearly dependent if at least one of the vectors in the set can be defined as a linear combination of the others. If this is not true, the vectors are said to be linearly independent.
\newline
\newline
The span of a set $S$ of vectors in vector space is the smallest linear subspace that contains the set.

\subsection{linear equations}
A linear equation is an equation that may be put in the form with variables and coefficients, which are often real numbers.
The coefficients are considered the parameters of the equation, and can be arbitrary expressions.

\newpage

\section{Two}
\subsection{bases}
A set $B$ of elements in a vector space  $\textbf{V}$ is called a basis if every element of $\textbf{V}$ may be written in a unique way as a linear combination of elements of $B$.
\subsection{coordinates}
A coordinate vector is a representation of a vector as an ordered list of numbers that describes the vector in terms of a particular
ordered basis.
\subsection{dimension}

\newpage

\section{Three}
\subsection{linear transformations}
A linear map is a mapping $V \to W$ between two modules that preserves the operations of addition and scalar multiplication.
When $V = W$, we call this an endomorphism of V.
\subsection{rank}
The rank of a matrix is the dimension of the vector space generated by its columns.
\subsection{change of coordinate matrices}

\newpage

\section{Four}
\subsection{matrices}
\subsection{systems of linear equations}

\newpage

\section{Five}
\subsection{determinants}
\subsection{characteristic polynomial}
\subsection{eigenvalues and eigenvectors}
Vectors that do not change span after a linear transformation.

\newpage

\section{Six}
\subsection{invariant subspaces}
\subsection{Cayley-Hamilton Theorem}

\end{document}
